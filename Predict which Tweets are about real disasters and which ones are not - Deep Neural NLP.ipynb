{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict which Tweets are about real disasters and which ones are not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2808</td>\n",
       "      <td>4039</td>\n",
       "      <td>disaster</td>\n",
       "      <td>Alexandria, VA</td>\n",
       "      <td>Four Technologies That Could Let Humans Surviv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7142</td>\n",
       "      <td>10234</td>\n",
       "      <td>volcano</td>\n",
       "      <td>Ted&amp;Qz Inc, Ireland, Europe</td>\n",
       "      <td>@songhey89 well I'm also gay but girls like so...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5030</td>\n",
       "      <td>7173</td>\n",
       "      <td>mudslide</td>\n",
       "      <td>plymouth</td>\n",
       "      <td>@brobread looks like mudslide????</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1001</td>\n",
       "      <td>1453</td>\n",
       "      <td>body%20bagging</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm not a Drake fan but I enjoy seeing him bod...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2601</td>\n",
       "      <td>3735</td>\n",
       "      <td>destroyed</td>\n",
       "      <td>Boise, Idaho</td>\n",
       "      <td>70 years after #ABomb destroyd #HiroshimaÛÓ#B...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id         keyword                     location  \\\n",
       "2808   4039        disaster               Alexandria, VA   \n",
       "7142  10234         volcano  Ted&Qz Inc, Ireland, Europe   \n",
       "5030   7173        mudslide                     plymouth   \n",
       "1001   1453  body%20bagging                          NaN   \n",
       "2601   3735       destroyed                 Boise, Idaho   \n",
       "\n",
       "                                                   text  target  \n",
       "2808  Four Technologies That Could Let Humans Surviv...       0  \n",
       "7142  @songhey89 well I'm also gay but girls like so...       0  \n",
       "5030                  @brobread looks like mudslide????       1  \n",
       "1001  I'm not a Drake fan but I enjoy seeing him bod...       0  \n",
       "2601  70 years after #ABomb destroyd #HiroshimaÛÓ#B...       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tweets = pd.read_csv('train.csv')\n",
    "train_tweets = train_tweets.sample(frac = 1)\n",
    "train_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>review_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2808</td>\n",
       "      <td>4039</td>\n",
       "      <td>disaster</td>\n",
       "      <td>Alexandria, VA</td>\n",
       "      <td>Four Technologies That Could Let Humans Surviv...</td>\n",
       "      <td>0</td>\n",
       "      <td>four technologies could let humans survive env...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7142</td>\n",
       "      <td>10234</td>\n",
       "      <td>volcano</td>\n",
       "      <td>Ted&amp;Qz Inc, Ireland, Europe</td>\n",
       "      <td>@songhey89 well I'm also gay but girls like so...</td>\n",
       "      <td>0</td>\n",
       "      <td>well also gay girls like predict tsunami amp v...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5030</td>\n",
       "      <td>7173</td>\n",
       "      <td>mudslide</td>\n",
       "      <td>plymouth</td>\n",
       "      <td>@brobread looks like mudslide????</td>\n",
       "      <td>1</td>\n",
       "      <td>brobread looks like mudslide</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1001</td>\n",
       "      <td>1453</td>\n",
       "      <td>body%20bagging</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm not a Drake fan but I enjoy seeing him bod...</td>\n",
       "      <td>0</td>\n",
       "      <td>drake fan enjoy seeing body bagging people gre...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2601</td>\n",
       "      <td>3735</td>\n",
       "      <td>destroyed</td>\n",
       "      <td>Boise, Idaho</td>\n",
       "      <td>70 years after #ABomb destroyd #HiroshimaÛÓ#B...</td>\n",
       "      <td>1</td>\n",
       "      <td>years abomb destroyd bbc looks wht survived ht...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id         keyword                     location  \\\n",
       "2808   4039        disaster               Alexandria, VA   \n",
       "7142  10234         volcano  Ted&Qz Inc, Ireland, Europe   \n",
       "5030   7173        mudslide                     plymouth   \n",
       "1001   1453  body%20bagging                          NaN   \n",
       "2601   3735       destroyed                 Boise, Idaho   \n",
       "\n",
       "                                                   text  target  \\\n",
       "2808  Four Technologies That Could Let Humans Surviv...       0   \n",
       "7142  @songhey89 well I'm also gay but girls like so...       0   \n",
       "5030                  @brobread looks like mudslide????       1   \n",
       "1001  I'm not a Drake fan but I enjoy seeing him bod...       0   \n",
       "2601  70 years after #ABomb destroyd #HiroshimaÛÓ#B...       1   \n",
       "\n",
       "                                             clean_text  review_length  \n",
       "2808  four technologies could let humans survive env...             10  \n",
       "7142  well also gay girls like predict tsunami amp v...             14  \n",
       "5030                       brobread looks like mudslide              4  \n",
       "1001  drake fan enjoy seeing body bagging people gre...             10  \n",
       "2601  years abomb destroyd bbc looks wht survived ht...             17  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def train_tweets_cleaning(doc):\n",
    "    train_tweets['clean_text'] = doc.apply(lambda x : ' '.join(text_to_word_sequence(x)))\n",
    "    train_tweets['clean_text'] = train_tweets['clean_text'].apply(lambda y : ' '.join([y for y in y.split() if not y in stop_words]))\n",
    "    train_tweets['clean_text'] = train_tweets['clean_text'].apply(lambda z : ' '.join([z for z in z.split() if len(z) > 1]))\n",
    "    train_tweets['clean_text'] = train_tweets['clean_text'].apply(lambda w : ' '.join([w for w in w.split() if w.isalpha()]))\n",
    "    train_tweets['review_length'] = train_tweets['clean_text'].apply(lambda v : len([v for v in v.split()]))\n",
    "\n",
    "train_tweets_cleaning(train_tweets['text'])\n",
    "train_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_independent = train_tweets['clean_text']\n",
    "Y_target = train_tweets['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_independent, Y_target, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "length = max(train_tweets['review_length'])\n",
    "print(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2308  4739  2309 ...     0     0     0]\n",
      " [  580   144   161 ...     0     0     0]\n",
      " [ 4741    86   187 ...     0     0     0]\n",
      " ...\n",
      " [  178    52 12585 ...     0     0     0]\n",
      " [  922   394   364 ...     0     0     0]\n",
      " [12588  4717  1225 ...     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def create_tokenizer(X_train_lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(X_train_lines)\n",
    "    return tokenizer\n",
    "# encode a list of lines\n",
    "def encode_text(tokenizer,X_train_lines,length):\n",
    "    # integer encode\n",
    "    encoded = tokenizer.texts_to_sequences(X_train_lines)\n",
    "    # pad encoded sequences\n",
    "    padded = pad_sequences(encoded,maxlen = length,padding = 'post')\n",
    "    return padded\n",
    "\n",
    "tokenizer = create_tokenizer(X_train)\n",
    "X_train_padded = encode_text(tokenizer,X_train,length)\n",
    "print(X_train_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 12589\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 23)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 23)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            (None, 23)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, 23, 100)      1258900     input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (None, 23, 100)      1258900     input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_9 (Embedding)         (None, 23, 100)      1258900     input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 20, 32)       12832       embedding_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 20, 32)       12832       embedding_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 20, 32)       12832       embedding_9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 20, 32)       0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 20, 32)       0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 20, 32)       0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (None, 10, 32)       0           dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1D)  (None, 10, 32)       0           dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1D)  (None, 10, 32)       0           dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 320)          0           max_pooling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 320)          0           max_pooling1d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)             (None, 320)          0           max_pooling1d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 960)          0           flatten_7[0][0]                  \n",
      "                                                                 flatten_8[0][0]                  \n",
      "                                                                 flatten_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 10)           9610        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            11          dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 3,824,817\n",
      "Trainable params: 3,824,817\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/3\n",
      " - 16s - loss: 0.6390 - accuracy: 0.6367\n",
      "Epoch 2/3\n",
      " - 14s - loss: 0.3451 - accuracy: 0.8659\n",
      "Epoch 3/3\n",
      " - 15s - loss: 0.1112 - accuracy: 0.9637\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1953fc1adc8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.merge import concatenate\n",
    "\n",
    "# define the model\n",
    "def define_model(length,vocab_size):\n",
    "    # channel 1\n",
    "    inputs1 = Input(shape = (length,))\n",
    "    embedding1 = Embedding(vocab_size,100)(inputs1)\n",
    "    conv1 = Conv1D(filters = 32, kernel_size = 4, activation = 'relu')(embedding1)\n",
    "    drop1 = Dropout(0.5)(conv1)\n",
    "    pool1 = MaxPooling1D(pool_size = 2)(drop1)\n",
    "    flat1 = Flatten()(pool1)\n",
    "    \n",
    "    # channel 2\n",
    "    inputs2 = Input(shape = (length,))\n",
    "    embedding2 = Embedding(vocab_size,100)(inputs2)\n",
    "    conv2 = Conv1D(filters = 32, kernel_size = 4, activation = 'relu')(embedding2)\n",
    "    drop2 = Dropout(0.5)(conv2)\n",
    "    pool2 = MaxPooling1D(pool_size = 2)(drop2)\n",
    "    flat2 = Flatten()(pool2)\n",
    "    \n",
    "    # channel 1\n",
    "    inputs3 = Input(shape = (length,))\n",
    "    embedding3 = Embedding(vocab_size,100)(inputs3)\n",
    "    conv3 = Conv1D(filters = 32, kernel_size = 4, activation = 'relu')(embedding3)\n",
    "    drop3 = Dropout(0.5)(conv3)\n",
    "    pool3 = MaxPooling1D(pool_size = 2)(drop3)\n",
    "    flat3 = Flatten()(pool3)\n",
    "    \n",
    "    # merge\n",
    "    merged = concatenate([flat1,flat2,flat3])\n",
    "    # interpretation\n",
    "    dense1 = Dense(10,activation = 'relu')(merged)\n",
    "    outputs = Dense(1, activation = 'sigmoid')(dense1)\n",
    "    model = Model(inputs = [inputs1,inputs2,inputs3], outputs = outputs)\n",
    "    # compile\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = 'adam',metrics = ['accuracy'])\n",
    "    # summarize\n",
    "    model.summary()\n",
    "    #plot_model(model,show_shapes = True,to_file = 'multichannel.png')\n",
    "    return model\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('Vocabulary Size: %d' % vocab_size)\n",
    "\n",
    "# define model\n",
    "model = define_model(length,vocab_size)\n",
    "\n",
    "# fit model\n",
    "model.fit([X_train_padded,X_train_padded,X_train_padded],y_train, epochs = 3, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 98.27\n",
      "Test Accuracy: 78.39\n"
     ]
    }
   ],
   "source": [
    "# evaluate model on test dataset\n",
    "X_test_padded = encode_text(tokenizer,X_test,length)\n",
    "\n",
    "_,acc = model.evaluate([X_train_padded,X_train_padded,X_train_padded],y_train,verbose = 0)\n",
    "print('Train Accuracy: %.2f' %(acc*100))\n",
    "_,acc = model.evaluate([X_test_padded,X_test_padded,X_test_padded],y_test,verbose = 0)\n",
    "print('Test Accuracy: %.2f' %(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tweets = pd.read_csv('test.csv')\n",
    "test_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>review_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>happened terrible car crash</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>heard earthquake different cities stay safe ev...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>forest fire spot pond geese fleeing across str...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>apocalypse lighting spokane wildfires</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "      <td>typhoon soudelor kills china taiwan</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash   \n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...   \n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...   \n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires   \n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan   \n",
       "\n",
       "                                          clean_text  review_length  \n",
       "0                        happened terrible car crash              4  \n",
       "1  heard earthquake different cities stay safe ev...              7  \n",
       "2  forest fire spot pond geese fleeing across str...             10  \n",
       "3              apocalypse lighting spokane wildfires              4  \n",
       "4                typhoon soudelor kills china taiwan              5  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_tweets_cleaning(doc_test_data):\n",
    "    test_tweets['clean_text'] = doc_test_data.apply(lambda x : ' '.join(text_to_word_sequence(x)))\n",
    "    test_tweets['clean_text'] = test_tweets['clean_text'].apply(lambda y : ' '.join([y for y in y.split() if not y in stop_words]))\n",
    "    test_tweets['clean_text'] = test_tweets['clean_text'].apply(lambda z : ' '.join([z for z in z.split() if len(z) > 1]))\n",
    "    test_tweets['clean_text'] = test_tweets['clean_text'].apply(lambda w : ' '.join([w for w in w.split() if w.isalpha()]))\n",
    "    test_tweets['review_length'] = test_tweets['clean_text'].apply(lambda v : len([v for v in v.split()]))\n",
    "\n",
    "test_tweets_cleaning(test_tweets['text'])\n",
    "test_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 744 2975   53 ...    0    0    0]\n",
      " [ 235  125 1027 ...    0    0    0]\n",
      " [  85    6  660 ...    0    0    0]\n",
      " ...\n",
      " [ 909  590  203 ...    0    0    0]\n",
      " [6654  310  229 ...    0    0    0]\n",
      " [4129 1699 1072 ...    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "test_padded = encode_text(tokenizer,test_tweets['clean_text'],length)\n",
    "print(test_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7139897\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict([test_padded,test_padded,test_padded],verbose = 0)\n",
    "# retrieve predicted percentage and label\n",
    "percent_pos = yhat[0,0]\n",
    "print(percent_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7139897 ],\n",
       "       [0.92849684],\n",
       "       [0.9702349 ],\n",
       "       ...,\n",
       "       [0.75614667],\n",
       "       [0.907746  ],\n",
       "       [0.8372651 ]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i in yhat:\n",
    "    percent_pos = np.round(i[0])\n",
    "    labels.append(percent_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>review_length</th>\n",
       "      <th>label</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>happened terrible car crash</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>heard earthquake different cities stay safe ev...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>forest fire spot pond geese fleeing across str...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>apocalypse lighting spokane wildfires</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "      <td>typhoon soudelor kills china taiwan</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash   \n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...   \n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...   \n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires   \n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan   \n",
       "\n",
       "                                          clean_text  review_length  label  \\\n",
       "0                        happened terrible car crash              4      1   \n",
       "1  heard earthquake different cities stay safe ev...              7      1   \n",
       "2  forest fire spot pond geese fleeing across str...             10      1   \n",
       "3              apocalypse lighting spokane wildfires              4      0   \n",
       "4                typhoon soudelor kills china taiwan              5      1   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       0  \n",
       "4       1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tweets['target'] = labels\n",
    "test_tweets['target'] = test_tweets['target'].astype('int')\n",
    "test_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0       1\n",
       "1   2       1\n",
       "2   3       1\n",
       "3   9       0\n",
       "4  11       1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission = test_tweets[['id','target']]\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv('submission.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
